{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_file.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5sPnmX1K8BoF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNmIHJ3MsjMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################################################\n",
        "# Decryption of Enigma coded strings\n",
        "#########################################################\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Part of coding challenge for Scale AI ML Role\n",
        "# Github link: https://github.com/hkhoont/scale_ai_engima_machine\n",
        "# email: hsk2147@columbia.edu\n",
        "# -----------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGp1jg3DTbu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "link=\"https://drive.google.com/open?id=1ApOOStHi7clwdZesQ_hNVWqjtEWa6-lp\"\n",
        "_,id=link.split(\"=\")\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('layers2_hiddensize64_batchsize32_saved_model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sPnmX1K8BoF",
        "colab_type": "text"
      },
      "source": [
        "## A - Installing  and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8amUMvWrGKi",
        "colab_type": "code",
        "outputId": "aedcbefb-8d3c-49ac-84ac-047b5fd0865f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install py-enigma\n",
        "!pip install faker\n",
        "!pip install tensorboardX==1.4\n",
        "!pip install tqdm\n",
        "!pip install hide_code"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py-enigma in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from faker) (1.12.0)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from faker) (1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.6.1)\n",
            "Requirement already satisfied: tensorboardX==1.4 in /usr/local/lib/python3.6/dist-packages (1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.4) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.4) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.4) (1.17.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX==1.4) (42.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: hide_code in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hide_code) (1.0.0)\n",
            "Requirement already satisfied: pdfkit in /usr/local/lib/python3.6/dist-packages (from hide_code) (0.6.1)\n",
            "Requirement already satisfied: nbconvert>=5.0 in /usr/local/lib/python3.6/dist-packages (from hide_code) (5.6.1)\n",
            "Requirement already satisfied: notebook>=5.1 in /usr/local/lib/python3.6/dist-packages (from hide_code) (5.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hide_code) (7.5.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hide_code) (4.6.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hide_code) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hide_code) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (4.3.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (0.4.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (2.1.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (2.10.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (4.6.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (3.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (0.8.4)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.0->hide_code) (5.0.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook>=5.1->hide_code) (5.3.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=5.1->hide_code) (0.8.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.1->hide_code) (4.5.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=5.1->hide_code) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hide_code) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hide_code) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hide_code) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.0->hide_code) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.0->hide_code) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert>=5.0->hide_code) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.0->hide_code) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.0->hide_code) (2.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=5.1->hide_code) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=5.1->hide_code) (2.6.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook>=5.1->hide_code) (0.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hide_code) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hide_code) (42.0.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hide_code) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hide_code) (4.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hide_code) (0.1.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQFm1qb_rOE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from typing import List, Tuple\n",
        "from enigma.machine import EnigmaMachine\n",
        "from faker import Faker\n",
        "import re\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange, tqdm\n",
        "from time import sleep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhLDj9SY8MM6",
        "colab_type": "text"
      },
      "source": [
        "## B - Helper functions already provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFnkSrI3rIRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConfiguredMachine:\n",
        "    def __init__(self):\n",
        "        self.machine = EnigmaMachine.from_key_sheet(\n",
        "            rotors='II IV V',\n",
        "            reflector='B',\n",
        "            ring_settings=[1, 20, 11],\n",
        "            plugboard_settings='AV BS CG DL FU HZ IN KM OW RX')\n",
        "\n",
        "    def reset(self):\n",
        "        self.machine.set_display('WXC')\n",
        "\n",
        "    def encode(self, plain_str: str) -> str:\n",
        "        self.reset()\n",
        "        return self.machine.process_text(plain_str)\n",
        "\n",
        "    def batch_encode(self, plain_list: List[str]) -> List[str]:\n",
        "        encoded = list()\n",
        "        for s in plain_list:\n",
        "            encoded.append(self.encode(s))\n",
        "        return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLzwW54crLAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(input_str):\n",
        "    return re.sub('[^a-zA-Z]', '', input_str).upper()\n",
        "\n",
        "def generate_data(batch_size: int, seq_len: int = 42) -> Tuple[List[str], List[str]]:\n",
        "    fake = Faker()\n",
        "    machine = ConfiguredMachine()\n",
        "\n",
        "    plain_list = fake.texts(nb_texts=batch_size, max_nb_chars=seq_len)\n",
        "    plain_list = [pre_process(p) for p in plain_list]\n",
        "    cipher_list = machine.batch_encode(plain_list)\n",
        "    return plain_list, cipher_list\n",
        "\n",
        "def str_score(str_a: str, str_b: str) -> float:\n",
        "    if len(str_a) != len(str_b):\n",
        "        return 0\n",
        "    n_correct = 0\n",
        "    for a, b in zip(str_a, str_b):\n",
        "        n_correct += int(a == b)\n",
        "    return n_correct / len(str_a)\n",
        "\n",
        "def score(predicted_plain: List[str], correct_plain: List[str]) -> float:\n",
        "    correct = 0\n",
        "    for p, c in zip(predicted_plain, correct_plain):\n",
        "        if str_score(p, c) > 0.8:\n",
        "            correct += 1\n",
        "    return correct / len(correct_plain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s-jn20-d3--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_characters = \"#ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "vocab = {}\n",
        "for i,char in enumerate(all_characters):\n",
        "    vocab[i]=char\n",
        "\n",
        "n_characters = len(all_characters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPK8fD-Kc24z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(cipher_list: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Solution\n",
        "    Input: Plain string with length <42\n",
        "    Output: Decryption of the string according to Enigma machine(as configured above). Size of decryption should be same as input string\n",
        "    \"\"\"\n",
        "    model = torch.load('/content/layers2_hiddensize64_batchsize32_saved_model.pth')\n",
        "    x_length = []\n",
        "    for i in plain:\n",
        "        x_length.append(len(i))\n",
        "    x_length = torch.FloatTensor(x_length)\n",
        "\n",
        "    x = torch.LongTensor(len(cipher_list), 42)\n",
        "    for i in range(len(cipher_list)):\n",
        "        x[i] = string_to_tensor(cipher_list[i])\n",
        "    x = Variable(x)\n",
        "\n",
        "    y_pred=model(x.long(),x_length)\n",
        "    n_y_pred,_ = numerical_string(len(cipher_list),y_pred,cipher_list,x_length)\n",
        "    # for i in range(len(cipher_list)):\n",
        "    #     print(n_y_pred[i],cipher_list[i])\n",
        "    return n_y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IykEwvJfcZBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerical_string(batch_size,y_pred,y_batch_string,x_length):\n",
        "    \"\"\"\n",
        "    Converts tensor output to String form\n",
        "    \"\"\"\n",
        "    x_length_array = x_length.detach().numpy().astype('int') \n",
        "    m = max(x_length_array)\n",
        "    y_pred = y_pred.view(batch_size,m,27)\n",
        "    n_y_pred = []\n",
        "\n",
        "    for k in range(batch_size):\n",
        "        string_pred = \"\" \n",
        "        for i in range(x_length_array[k]):\n",
        "            string_pred = string_pred+vocab[np.argmax(y_pred[k][i].detach().numpy())]\n",
        "\n",
        "        n_y_pred.append(string_pred)\n",
        "\n",
        "    return n_y_pred,y_batch_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbNDah_3arOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turning a string into a tensor\n",
        "def string_to_tensor(string):\n",
        "    \"\"\"\n",
        "    Convert string into numerical torch tensor filled with index according to above mentioned 'all_characters' variable\n",
        "    Input: String of capital letters to be dencrypted \n",
        "    Output: Torch tensor(torch.size(42)) \n",
        "    \"\"\"\n",
        "    tensor = torch.zeros(42).long()\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        except:\n",
        "            continue\n",
        "    return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btEvTtEoakNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,output_size, n_layers):\n",
        "        super(CharLSTM, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        padding_idx = 0\n",
        "\n",
        "        # Encoder embedding layer is used to convert batch text in one-hot encode form\n",
        "        # Since its one-hot encoded (vocal size = 27), there no need to learn the embeddings\n",
        "        self.encoder = nn.Embedding(num_embeddings=self.input_size,\n",
        "                                    embedding_dim=self.input_size,\n",
        "                                    padding_idx=padding_idx,)\n",
        "        self.encoder.weight.data = torch.eye(self.input_size)\n",
        "        self.encoder.weight.requires_grad = False\n",
        "\n",
        "        # LSTM Unit\n",
        "        self.lstm = nn.LSTM(self.input_size, \n",
        "                           hidden_size, \n",
        "                           n_layers, \n",
        "                           batch_first=True)\n",
        "        \n",
        "        #Decoder\n",
        "        self.decoder = nn.Linear(hidden_size, \n",
        "                                 output_size)\n",
        "        \n",
        "    def forward(self, x, x_length):\n",
        "\n",
        "        # print(\"Max in x_length\",max(x_length))\n",
        "        batch_size_input = x_length.shape[0]\n",
        "        self.hidden = self.init_hidden(batch_size_input)                        # Initialize the weights\n",
        "        x = self.encoder(x)                                                     # Encoder\n",
        "\n",
        "        # print(\"/CharLSTM/forward/ Size: x after encoder - \",x.shape)\n",
        "\n",
        "        #Pack Padding will ensure that forward pass is carried for only units equal to length of string \n",
        "        x = torch.nn.utils.rnn.pack_padded_sequence(x, \n",
        "                                                    x_length, \n",
        "                                                    batch_first=True,\n",
        "                                                    enforce_sorted=False)\n",
        "        \n",
        "        x, self.hidden = self.lstm(x, self.hidden)                              # Running the LSTM Unit\n",
        "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "        # print(\"/CharLSTM/forward/ Size: x after pad - \",x.shape)\n",
        "\n",
        "        x = x.contiguous()\n",
        "        x = x.view(-1, x.shape[2])\n",
        "        # print(\"/CharLSTM/forward/ Size: x after view - \",x.shape)\n",
        "        x = self.decoder(x)                                                     # Decoder\n",
        "        # print(\"/CharLSTM/forward/ Size: x after decoder - \",x.shape)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        # x = F.softmax(x, dim=1)\n",
        "\n",
        "        Y_hat = x\n",
        "        return Y_hat\n",
        "\n",
        "\n",
        "    def init_hidden(self,batch_size_input):\n",
        "        \"\"\"\n",
        "        Initial the weights\n",
        "        Method: Random\n",
        "        \"\"\"\n",
        "        hidden_a = torch.zeros(self.n_layers,batch_size_input, self.hidden_size)\n",
        "        hidden_b = torch.zeros(self.n_layers,batch_size_input, self.hidden_size)\n",
        "\n",
        "        hidden_a = Variable(hidden_a)\n",
        "        hidden_b = Variable(hidden_b)\n",
        "\n",
        "        return (hidden_a, hidden_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0QjC_gqZPQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a822342f-4c46-4984-e51a-66af68729547"
      },
      "source": [
        "plain,cipher = generate_data(16384)\n",
        "score(predict(cipher), plain)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnfE730HdJ1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}