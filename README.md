# Scale AI Engima_machine coding assignment
Learning the Enigma with LSTM
## Problem Statement ##

Implement a deep sequence model that can decrypt messages from an enigma machine. The messages can be up to 42 characters in length. Do not use an unnecessarily large network, anything more than 60K parameter is overkill.
You are expected to achieve a score of 0.9, feel free to predict longer sequences as a stretch goal.

## Contents of the repo ##

1. Readme file
2. Helper Functions provided [cipher_take_home_py]()
3. Jupyter Notebook - Overall: [Google Collab Notebook]() [main_file.ipynb]()
4. Jupyter Notebook - Only testing by load saved model: [Google Collab Notebook]() [test_file.ipynb]()


## How to run the files and get the results ##

1. Overall File
    * Run the Python notebook on Google Collab. Particular instructions are mentioned in notebook
2. Test File
    * Run the Python notebook on Google Collab. Particular instructions are mentioned in notebook

## Model ##

1)   *(done)*
2)  *(addressed)*
